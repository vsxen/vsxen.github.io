<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Code Life</title>
    <link>https://vsxen.github.io/</link>
    <description>Recent content on Code Life</description>
    <image>
      <title>Code Life</title>
      <url>https://vsxen.github.io/images/papermod-cover.png</url>
      <link>https://vsxen.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.148.2</generator>
    <language>zh</language>
    <copyright>PaperMod Contributors</copyright>
    <lastBuildDate>Wed, 06 Aug 2025 00:05:12 +0800</lastBuildDate>
    <atom:link href="https://vsxen.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2025 08 10</title>
      <link>https://vsxen.github.io/posts/2025-08-10/</link>
      <pubDate>Wed, 06 Aug 2025 00:05:12 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-08-10/</guid>
      <description></description>
    </item>
    <item>
      <title>k3s and wsl</title>
      <link>https://vsxen.github.io/posts/2025-08-03/</link>
      <pubDate>Tue, 29 Jul 2025 10:27:29 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-08-03/</guid>
      <description>&lt;p&gt;这一周好忙&lt;/p&gt;
&lt;p&gt;新公司的网络居然可以直连谷歌，香港的出口IP，Zenlayer的线路哈哈，而且还能直接用Gemini神奇。&lt;/p&gt;
&lt;p&gt;发现git默认生成的密钥对改成了ed25519，问了下AI如下：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh-keygen&lt;/code&gt; 是一个非常实用的命令行工具，用于生成 &lt;strong&gt;SSH (Secure Shell)&lt;/strong&gt; 协议使用的密钥对。这个密钥对通常由一个&lt;strong&gt;私钥&lt;/strong&gt;和一个&lt;strong&gt;公钥&lt;/strong&gt;组成。它们是 SSH 安全通信的基石，允许用户在不传输密码的情况下安全地认证到远程服务器。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;密钥对的核心概念&#34;&gt;密钥对的核心概念&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;公钥 (Public Key)：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;这是您可以&lt;strong&gt;安全地共享&lt;/strong&gt;给任何人的部分。&lt;/li&gt;
&lt;li&gt;您需要将它放在您想要连接的远程服务器上（通常在 &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt; 文件中）。&lt;/li&gt;
&lt;li&gt;公钥用于&lt;strong&gt;加密&lt;/strong&gt;数据，并且可以&lt;strong&gt;验证&lt;/strong&gt;私钥签名的数据。&lt;/li&gt;
&lt;li&gt;它不能用来解密数据或进行身份认证，只能用于验证私钥持有者的身份。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;私钥 (Private Key)：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;这是您需要&lt;strong&gt;严格保密&lt;/strong&gt;的部分。绝不能与任何人共享。&lt;/li&gt;
&lt;li&gt;它通常存储在您的本地计算机上（例如 &lt;code&gt;~/.ssh/id_rsa&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;私钥用于&lt;strong&gt;解密&lt;/strong&gt;由对应公钥加密的数据，并用于向远程服务器&lt;strong&gt;签名&lt;/strong&gt;认证请求。&lt;/li&gt;
&lt;li&gt;如果私钥泄露，您的 SSH 连接安全就会受到威胁。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ssh-keygen-的基本用法&#34;&gt;&lt;code&gt;ssh-keygen&lt;/code&gt; 的基本用法&lt;/h3&gt;
&lt;p&gt;最简单的生成命令是：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ssh-keygen
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;执行这个命令后，&lt;code&gt;ssh-keygen&lt;/code&gt; 会引导您完成以下几个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;文件保存路径：&lt;/strong&gt; 它会提示您选择密钥对的保存位置。默认情况下，私钥会保存在 &lt;code&gt;~/.ssh/id_rsa&lt;/code&gt;（对于 RSA 算法）或 &lt;code&gt;~/.ssh/id_ed25519&lt;/code&gt;（对于 Ed25519 算法），公钥则会是相同路径加上 &lt;code&gt;.pub&lt;/code&gt; 后缀（例如 &lt;code&gt;~/.ssh/id_rsa.pub&lt;/code&gt;）。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Enter file in which to save the key (/home/user/.ssh/id_rsa):
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果您不输入任何内容直接回车，就会使用默认路径。如果您想生成多个密钥对用于不同目的，可以输入不同的文件名。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;密码短语 (Passphrase)：&lt;/strong&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Enter passphrase (empty for no passphrase):
Enter same passphrase again:
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这是非常重要的一步。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作用：&lt;/strong&gt; 为您的&lt;strong&gt;私钥&lt;/strong&gt;加密。即使私钥文件被盗，没有密码短语也无法使用。这提供了额外的安全层。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;建议：&lt;/strong&gt; &lt;strong&gt;强烈建议&lt;/strong&gt;设置一个强密码短语。虽然每次使用私钥时都需要输入密码短语会增加一点点不便，但它能极大地提升安全性。您可以使用 &lt;code&gt;ssh-agent&lt;/code&gt; 来缓存密码短语，避免每次都输入。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;留空：&lt;/strong&gt; 如果您留空（不设置密码短语），私钥将不加密，这意味着任何获得该私钥文件的人都可以直接使用它。在自动化脚本等特定场景下可能会留空，但请务必了解其安全风险。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;密钥指纹和随机艺术图：&lt;/strong&gt;
生成完成后，&lt;code&gt;ssh-keygen&lt;/code&gt; 会显示密钥的&lt;strong&gt;指纹 (fingerprint)&lt;/strong&gt; 和一个随机生成的&lt;strong&gt;艺术图 (randomart image)&lt;/strong&gt;。这些信息用于视觉验证密钥的唯一性。&lt;/p&gt;</description>
    </item>
    <item>
      <title>CUDA 将支持RISC-V</title>
      <link>https://vsxen.github.io/posts/2025-07-27/</link>
      <pubDate>Tue, 22 Jul 2025 20:46:15 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-07-27/</guid>
      <description>&lt;p&gt;近日举办的2025 RISC-V中国峰会上，NVIDIA硬件工程副总裁Frans Sijstermans宣布，CUDA软件平台将支持RISC-V指令集架构处理器，为开源架构RISC-V开启进入数据中心与AI市场的大门。&lt;/p&gt;
&lt;p&gt;遗憾的是，Go 的 C 语言 FFI 实在太差了。cgo 的糟糕程度怎么说都不为过。&lt;/p&gt;
&lt;p&gt;使用Gemini cli 尝试做一个自动抓取公司技术博客的应用。&lt;/p&gt;
&lt;p&gt;Qwen-codeer 发布了，效果还可以，比Qwen好一些，但是有点贵&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/debugging-the-one-in-a-million-failure-migrating-pinterests-search-infrastructure-to-kubernetes-bef9af9dabf4&#34;&gt;调试百万分之一的故障：将 Pinterest 的搜索基础设施迁移到 Kubernetes&lt;/a&gt;，&lt;/p&gt;
&lt;p&gt;指标 container_referenced_bytes 在 cAdvisor 中默认启用，用于跟踪进程在每个测量周期中引用的总内存字节数。该指标通过 PTE 访问位机制实现了 Brendan Gregg 的工作集大小（WSS）估计，该机制使用页表中的访问位来计算进程读取或写入的总内存量。每次 cAdvisor 运行时，它会扫描整个页表来计算此统计数据，通过统计所有条目中的所有访问位，然后清除每个已访问的位。PinCompute 每 30 秒运行一次 cAdvisor，这意味着这种侵入性的访问位检查和清除每分钟发生两次，每分钟一次。&lt;/p&gt;
&lt;p&gt;Manas 搜索索引每个叶节点可能高达数百 GB，而二级排序索引可能超过 1TB。当 Manas 叶节点启动时，它们会将整个索引映射到内存中。这意味着内存使用可能非常显著（例如，对于内存使用量为 100GB 的主机，页表可以容纳 2500 万个条目）。每 30 秒遍历并清除 2500 万个页表条目可能会确实导致与内存密集型叶处理产生竞争。&lt;/p&gt;</description>
    </item>
    <item>
      <title>kimi k2 发布</title>
      <link>https://vsxen.github.io/posts/2025-07-20/</link>
      <pubDate>Wed, 16 Jul 2025 15:08:22 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-07-20/</guid>
      <description>&lt;p&gt;Kimi K2 是一款具备更强代码能力、更擅长通用 Agent 任务的 MoE 架构基础模型，总参数 1T，激活参数 32B。&lt;/p&gt;
&lt;p&gt;在 SWE Bench Verified、Tau2、AceBench 等基准性能测试中，Kimi K2 均取得开源模型中的 SOTA 成绩，展现出在代码、Agent、数学推理任务上的领先能力。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/1927140506573435010&#34;&gt;知乎提问&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在openrouter看到了groq，瞄了一下他们居然有自己的GPU。&lt;/p&gt;
&lt;p&gt;不过最近，GPU 的地位也在经受挑战：一家名为 Groq 的初创公司开发出了一种新的 AI 处理器 ——LPU（Language Processing Unit），其推理速度相较于英伟达 GPU 提高了 10 倍，成本却降低到十分之一。贾扬清在推特上算了一笔账，因为Groq小的可怜的内存容量（230MB），在运行Llama-2 70b模型时，需要305张Groq卡才足够，而用H100则只需要8张卡。从目前的价格来看，这意味着在同等吞吐量下，Groq的硬件成本是H100的40倍，能耗成本是10倍。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ml-explore/mlx/pull/1983&#34;&gt;Apple CPU的推理框架要支持CUDA了&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/cn/blogs/containers/under-the-hood-amazon-eks-ultra-scale-clusters/&#34;&gt;EKS 100k node&lt;/a&gt;，之前k8s官方说最大5k节点，openai说他们有10k节点，这篇文的写的不错，都是之前遇到的问题。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ahmet.im/blog/kubernetes-list-performance/&#34;&gt;和上文对应，介绍如何保障APIserver的稳定&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;opencode 好像火起来了，golang加ts写的。&lt;/p&gt;
&lt;p&gt;NFD 还可以探测操作系统的相关配置。&lt;/p&gt;
&lt;p&gt;谷歌DeepMind最近从OpenAI的潜在收购目标中挖走了Windsurf公司的核心团队，进一步增强了谷歌的AI技术实力，背后离不开戴密斯·哈萨比斯的操盘。&lt;/p&gt;</description>
    </item>
    <item>
      <title>故地重游与观海</title>
      <link>https://vsxen.github.io/posts/2025-07-13/</link>
      <pubDate>Mon, 07 Jul 2025 21:54:52 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-07-13/</guid>
      <description>&lt;p&gt;那么HBM内存究竟是什么，与现在主流的LPDDR5有何不同呢？事实上，HBM（High Bandwidth Memory，高带宽内存）是一种基于3D堆栈技术，通过TSV（硅通孔）和微凸块（ubump）工艺实现的多层DRAM芯片垂直堆叠。而DDR（Double Data Rate）则采用的是并行总线架构，常见于DIMM（双列直插式内存模块）形式。&lt;/p&gt;
&lt;p&gt;HBM的带宽究竟有多高呢？以最新的HBM3E为例，其传输速率达到了9.6GB/s，可提供1.2TB/s带宽。作为对比，LPDDR5X的带宽为8533Mbps（1066.6MB/s），也就是说HBM3E的带宽是LPDDR5X的1180倍。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://36kr.com/p/3365872192243719&#34;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;目前只有kubelet支持动态修改log level。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/microsandbox/microsandbox/&#34;&gt;用于LLM的沙盒环境&lt;/a&gt;，没想到背后是依赖libkrun，&lt;a href=&#34;http://github.com/containers&#34;&gt;containers&lt;/a&gt;组件下面的，后来看下了&lt;a href=&#34;https://developers.redhat.com/articles/2025/07/02/supercharging-ai-isolation-microvms-ramalama-libkrun#current_limitations_and_future_directions__gpu_enablement&#34;&gt;RedHat&lt;/a&gt;也有相关介绍。&lt;/p&gt;
&lt;p&gt;和集团那边沟通他们声称设计的推理集群最多只能支持32物理机节点，啊这有点不科学，天天都在听说什么万卡集群，这差的有点多吧。&lt;/p&gt;
&lt;p&gt;液冷服务器&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bentoml.com/llm/inference-optimization/data-tensor-pipeline-expert-hybrid-parallelism&#34;&gt;生产环境中的 LLM 推理&lt;/a&gt;， 这系列文章写的不错。&lt;/p&gt;
&lt;p&gt;试用了下perplexity，感觉一般，没有很惊讶。&lt;/p&gt;
&lt;p&gt;GORK 4 发布了。&lt;/p&gt;
&lt;h2 id=&#34;生活&#34;&gt;生活&lt;/h2&gt;
&lt;p&gt;已经提了离职，周五晚上到下周一去了趟青岛。&lt;/p&gt;
&lt;p&gt;电力如何调度的？这几天新闻说用电量一直达到历史新高。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gemini Deep Research</title>
      <link>https://vsxen.github.io/posts/2025-07-06/</link>
      <pubDate>Sat, 05 Jul 2025 15:45:23 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-07-06/</guid>
      <description>&lt;p&gt;体验过chatgpt，豆包，Qwen，和Gemini的深度研究之后，个人感觉Gemini是最好的。
首先会生成研究方向，搜索关键字，然后可能是通过tool call的方式抓取相关内容，生成的结果可以用来创建到Web Page（可交互），Infographic，Quiz和音频。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;../../images/deep-research.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;当 kube-apiserver 处理 LIST 请求时，它会一次性将数据序列化为 JSON 或 Protobuf 格式，然后交由底层的 Go/http 处理。根据标准的 encoding/json 库实现，kube-apiserver 需要分配一大块内存来存放完整的序列化结果。更严重的是，这块内存要等到数据的最后一个字节被传输完毕后才会释放，容易导致高峰时的内存占用激增。&lt;/p&gt;
&lt;p&gt;解决这个问题的关键在于引入 流式处理 来序列化数据。KEP-5116 根据 LIST 响应的结构特点，可以依次序列化 TypeMeta、ListMeta，然后逐项序列化 Items，避免一次性分配和持有大块内存，从而降低内存占用。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://fuweid.com/post/2025-streaming-jsonpb-in-k8s/&#34;&gt;Streaming JSON/Protobuf in Kubernetes&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;k8s 中 prometheus的 token 是如何访问经过认证的kube-controller-manager的/metrics的？&lt;/p&gt;
&lt;p&gt;答案是：&lt;strong&gt;证书验证（TLS）和Token授权（RBAC）是两个独立但连续的步骤。&lt;code&gt;kube-controller-manager&lt;/code&gt;自己处理TLS握手，但会将授权决策委托&lt;/strong&gt;给&lt;code&gt;kube-apiserver&lt;/code&gt;。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;认证 (Authentication) - 使用 &lt;code&gt;TokenReview&lt;/code&gt;&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kube-controller-manager&lt;/code&gt;接收到Token后，它会创建一个&lt;code&gt;TokenReview&lt;/code&gt;对象。这个对象包含了它从Prometheus收到的原始Token。&lt;/li&gt;
&lt;li&gt;它向&lt;code&gt;kube-apiserver&lt;/code&gt;的&lt;code&gt;/apis/authentication.k8s.io/v1/tokenreviews&lt;/code&gt;端点发起一个请求，内容就是这个&lt;code&gt;TokenReview&lt;/code&gt;对象。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kube-apiserver&lt;/code&gt;收到请求后，会验证这个Token的签名和有效性。如果Token有效，&lt;code&gt;kube-apiserver&lt;/code&gt;会在&lt;code&gt;TokenReview&lt;/code&gt;对象的状态（status）字段中填充该Token对应的用户信息（用户名、UID、所属组等），并返回给&lt;code&gt;kube-controller-manager&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;现在，&lt;code&gt;kube-controller-manager&lt;/code&gt;知道了这个请求的发起者是谁（例如，&lt;code&gt;system:serviceaccount:monitoring:prometheus-k8s&lt;/code&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;授权 (Authorization) - 使用 &lt;code&gt;SubjectAccessReview&lt;/code&gt;&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在知道了请求者的身份后，&lt;code&gt;kube-controller-manager&lt;/code&gt;需要确认这个身份是否有权限执行请求的操作（即对&lt;code&gt;/metrics&lt;/code&gt;路径进行&lt;code&gt;GET&lt;/code&gt;操作）。&lt;/li&gt;
&lt;li&gt;它会创建一个&lt;code&gt;SubjectAccessReview&lt;/code&gt;对象。这个对象里包含了上一步获取到的用户信息以及本次请求试图执行的操作（&lt;code&gt;verb: &amp;quot;get&amp;quot;&lt;/code&gt;, &lt;code&gt;nonResourceURL: &amp;quot;/metrics&amp;quot;&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;它向&lt;code&gt;kube-apiserver&lt;/code&gt;的&lt;code&gt;/apis/authorization.k8s.io/v1/subjectaccessreviews&lt;/code&gt;端点发起请求。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kube-apiserver&lt;/code&gt;收到请求后，会查询集群中所有的RBAC规则（&lt;code&gt;Role&lt;/code&gt;, &lt;code&gt;ClusterRole&lt;/code&gt;, &lt;code&gt;RoleBinding&lt;/code&gt;, &lt;code&gt;ClusterRoleBinding&lt;/code&gt;），判断这个用户是否有权限执行该操作。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kube-apiserver&lt;/code&gt;将检查结果（允许或拒绝）填充到&lt;code&gt;SubjectAccessReview&lt;/code&gt;对象的状态字段中，并返回给&lt;code&gt;kube-controller-manager&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;最终决策&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kube-controller-manager&lt;/code&gt;收到&lt;code&gt;SubjectAccessReview&lt;/code&gt;的响应后，如果结果是“允许”，它就会向Prometheus返回&lt;code&gt;/metrics&lt;/code&gt;的数据。&lt;/li&gt;
&lt;li&gt;如果结果是“拒绝”，它会向Prometheus返回&lt;code&gt;403 Forbidden&lt;/code&gt;错误。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这保证了整个集群的认证授权策略是统一和集中的，避免了每个组件各自为政带来的安全风险和管理复杂性。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;k8s 为什么要设计service/proxy的子资源?&lt;/p&gt;
&lt;p&gt;AI生成了4个理由，我觉得唯一有点说服力的也就第三条。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Artifact vs Canvas</title>
      <link>https://vsxen.github.io/posts/2025-06-29/</link>
      <pubDate>Sun, 29 Jun 2025 18:00:00 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-06-29/</guid>
      <description>&lt;p&gt;简单用了下claude artifact，效果如下：
&lt;img loading=&#34;lazy&#34; src=&#34;../../images/claude-artifact.png&#34;&gt;
我是普通账号，上下文长度有点短，生成之后就不能做修改了，步骤分解第一次是自己生成，截图这次是手动补充的。
后端接口接口不能直接发布，只能作为纯文本预览。&lt;/p&gt;
&lt;p&gt;同样的提示词在aistduio上面用Gemini 2.5 pro效果就差了一些：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;../../images/aistduio-build.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/vllm-project/production-stack&#34;&gt;https://github.com/vllm-project/production-stack&lt;/a&gt; vllm官方的最佳实践&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://letsencrypt.org/2025/07/01/issuing-our-first-ip-address-certificate/&#34;&gt;letsencrypt 准备颁发IP证书了&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gemini Cli 发布，可以免费用2.5 pro，超过以后会降到2.5 flash，还是比较良心的&lt;/p&gt;
&lt;p&gt;TensorFlow 现在是不是比不上pytorch了？&lt;/p&gt;
&lt;p&gt;曾几何时，TensorFlow是深度学习框架领域无可争议的王者。然而，近年来，战局已悄然改变。来自学术界和产业界的多方证据表明，由Meta AI（原Facebook AI Research）主导开发的PyTorch，在用户青睐度、社区活跃度和学术研究应用等多个关键指标上，已经超越了Google支持的TensorFlow。虽然TensorFlow在特定的工业生产环境中仍占有一席之地，但“PyTorch后来居上”已成为业界的普遍共识。&lt;/p&gt;
&lt;p&gt;学术界的压倒性优势与开发者的普遍偏爱
目前，PyTorch在学术研究领域的主导地位尤为突出。根据PyTorch官方在2024年底发布的回顾报告，超过70%的AI研究论文实现采用了PyTorch。这一数据得到了各大顶级AI会议论文代码实现的印证，PyTorch的出现频率远高于TensorFlow。这种趋势的背后，是PyTorch以其简洁、灵活和“Pythonic”的编程风格赢得了广大学者和开发者的心。&lt;/p&gt;
&lt;p&gt;工业界的版图变迁：从TensorFlow独大到两强并立
传统上，TensorFlow凭借其强大的生态系统，如用于模型部署的TensorFlow Serving、用于移动和嵌入式设备的TensorFlow Lite（TFLite）以及端到端机器学习平台TFX，在工业界，特别是大规模生产部署方面，占据了绝对优势。许多大型科技公司，包括Google自身，其内部大量的AI应用和系统都深度绑定了TensorFlow。&lt;/p&gt;
&lt;p&gt;然而，随着PyTorch的日渐成熟和其生态的不断完善，这一格局正在被打破。PyTorch在2.0版本后，通过引入torch.compile等功能，显著提升了训练性能，缩小了与TensorFlow在速度上的差距。同时，TorchServe等部署工具的推出，也补齐了其在生产环境中的短板。&lt;/p&gt;
&lt;p&gt;更重要的是，随着大量在校期间习惯使用PyTorch的学生和研究人员进入工业界，企业的新项目越来越倾向于采用PyTorch。许多公司，特别是那些追求快速迭代和创新的AI初创企业，已将PyTorch作为首选框架。虽然让拥有庞大TensorFlow技术栈的公司进行“伤筋动骨”的迁移尚不现实，但在新项目的选择上，天平已明显倾斜。&lt;/p&gt;
&lt;p&gt;Hugging Face生态的“风向标”意义
作为全球最大的AI模型和数据集社区，Hugging Face上模型的框架分布是衡量框架流行度的重要“风向标”。尽管没有精确的官方统计数据持续发布，但社区的普遍观察和模型上传趋势显示，绝大多数最新的、SOTA（State-of-the-Art）的自然语言处理（NLP）模型，尤其是大语言模型（LLMs），都优先提供PyTorch版本。这得益于Hugging Face的Transformers库与PyTorch的无缝集成。开发者可以轻松地使用PyTorch对Hugging Face上的模型进行微调和再训练，这极大地促进了PyTorch在NLP领域的统治地位。&lt;/p&gt;
&lt;p&gt;那什么又是 Pythonic 呢？&lt;/p&gt;
&lt;p&gt;cline 可以从Gemini cli中调用2.5 pro的接口的，后续又去掉了，哈哈。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/musistudio/claude-code-router&#34;&gt;https://github.com/musistudio/claude-code-router&lt;/a&gt; 想用claude code但是没有合适的购买途径，就可以用这个项目。&lt;/p&gt;
&lt;h2 id=&#34;生活&#34;&gt;生活&lt;/h2&gt;
&lt;p&gt;bilibili首页刷到了某豪车租赁的账号。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1R67GzsEQf/&#34;&gt;为啥AMD突然就把英特尔干趴了？&lt;/a&gt;Intel的股价快到历史新低了。&lt;/p&gt;</description>
    </item>
    <item>
      <title>如何离线下载音乐？</title>
      <link>https://vsxen.github.io/posts/2025-06-22/</link>
      <pubDate>Sun, 22 Jun 2025 15:54:51 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-06-22/</guid>
      <description>&lt;p&gt;DB-GPT 是真的一般呀，UI一般，经常还有报错。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://coroot.com/blog/engineering/using-ai-for-troubleshooting-openai-vs-deepseek/&#34;&gt;Using AI for Troubleshooting: OpenAI vs DeepSeek &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kaniko 终于正式归档了，构建工具用哪一个呢？&lt;/p&gt;
&lt;p&gt;Gemini Code Assist VSCode插件发布了，速度好慢。&lt;/p&gt;
&lt;p&gt;GPUmanager 分析，已经不维护了，后续推荐https://github.com/Project-HAMi。&lt;/p&gt;
&lt;p&gt;openrouter 还有一个free的模型。&lt;/p&gt;
&lt;p&gt;都说ragflow的rag功能比dify要好，测试了一下。&lt;/p&gt;
&lt;h2 id=&#34;生活&#34;&gt;生活&lt;/h2&gt;
&lt;p&gt;腾讯云智面试，字节面试，问了一个我觉得比较有意思的是问题：你对现在的架构最不满意/最想改进的地方是什么？
我回答的是集群要跨AZ。&lt;/p&gt;
&lt;p&gt;离线下载音乐，想听歌越来越难了&lt;/p&gt;
&lt;p&gt;存款利率迈入“1”时代，&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apple Container</title>
      <link>https://vsxen.github.io/posts/2025-06-15/</link>
      <pubDate>Sun, 15 Jun 2025 16:34:33 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-06-15/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://xxchan.me/ai/2025/05/06/claude-code.html&#34;&gt;Claude Code 内部工作原理窥探&lt;/a&gt;
写的很不错，里面还有一篇关于LLM思考的文章。&lt;/p&gt;
&lt;p&gt;引申出了另一个问题，Proxy和这种代理的对比：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;特性&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;普通隧道代理 (Tunneling Proxy)&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;解密/拦截代理 (Intercepting Proxy)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;能否看到明文&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;❌ &lt;strong&gt;不能&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;✅ &lt;strong&gt;可以&lt;/strong&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;工作模式&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;HTTP CONNECT&lt;/code&gt; 隧道模式&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;中间人攻击 (MITM) 模式&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;与服务器的连接&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;客户端与服务器端到端加密&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;代理分别与客户端和服务器建立加密连接&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;是否需要安装根证书&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;否&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;是 (关键步骤)&lt;/strong&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;主要用途&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;访问控制、IP 伪装、网络路由&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;网络调试、安全审计、数据修改&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;典型例子&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;多数商业 VPN 或普通网络代理&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Mitmproxy, Burp Suite, Charles&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这周是WWDC，发布了Apple Container，去年发布了 Hyper Framework，嗯macOS 开始成为最好的开发系统&lt;a href=&#34;https://github.com/apple/container&#34;&gt;Apple Container&lt;/a&gt;，看了下issue。还有MTU的问题。&lt;/p&gt;
&lt;p&gt;iOS 26 &amp;amp; &lt;a href=&#34;https://blog.google/products/android/android-16/&#34;&gt;Android 16&lt;/a&gt;
想整合多个vllm实例，搜索以后发现这个项目&lt;a href=&#34;https://github.com/BerriAI/litellm&#34;&gt;litellm&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;试用了Trae&lt;/p&gt;
&lt;p&gt;kube-proxy 的 nft 后端还是&lt;a href=&#34;https://github.com/kubernetes-sigs/knftables&#34;&gt;自己&lt;/a&gt;封装的？&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://3d.hunyuan.tencent.com/&#34;&gt;浑元3D&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>ChatDB和Text-to-SQL项目对比</title>
      <link>https://vsxen.github.io/posts/2025-06-08/</link>
      <pubDate>Sun, 08 Jun 2025 16:34:43 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-06-08/</guid>
      <description>&lt;p&gt;codex 用rust重写了，之前是用的nodejs&lt;/p&gt;
&lt;p&gt;使用clickhouse作为后端存储的 open telemetry相关方案，有空得对比一下，https://github.com/hyperdxio/hyperdx 。&lt;/p&gt;
&lt;p&gt;[从etcd的数据文件导出原始数据](&lt;a href=&#34;https://www.cncf.io/blog/2025/05/08/the-kubernetes-surgeons-handbook-precision-recovery-from-etcd-snap&#34;&gt;https://www.cncf.io/blog/2025/05/08/the-kubernetes-surgeons-handbook-precision-recovery-from-etcd-snap&lt;/a&gt;
shots/)，比如原始yaml。&lt;/p&gt;
&lt;p&gt;看了下Cloudflare AI Gateway相关功能。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/bincooo/chatgpt-adapter/discussions/106&#34;&gt;从GUI中逆向出相关接口并转换为OPENAI格式&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dataherald已经不维护了，vanna只是框架，需要二次开发。&lt;/p&gt;
&lt;p&gt;使用 Gemini自建Deep research &lt;a href=&#34;https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart&#34;&gt;https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;特斯拉表示，Dojo 是当前全球唯二现存的最大处理器之一。这种晶圆级芯片采用整片 300mm 晶圆制成，单芯片尺寸已达物理极限。&lt;/p&gt;
&lt;p&gt;由于 Dojo 大芯片的超高复杂性，即使在制造过程中也难以 100% 检测缺陷晶粒，而静默数据错误的检测更困难。&lt;/p&gt;
&lt;p&gt;虽然 SDC 在所有硬件上都难以避免，但 Dojo 处理器有着 8,850 个核心、18000A 电流及 15000W 的超高功耗，这会严重放大其影响，因此所有核心必须按设计运行，否则单个数据错误便可毁掉整个耗时数周才能完成 AI 训练成果。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://x.com/Tesla_AI/status/1930686196201714027&#34;&gt;https://x.com/Tesla_AI/status/1930686196201714027&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.servethehome.com/tesla-dojo-exa-scale-lossy-ai-network-using-the-tesla-transport-protocol-over-ethernet-ttpoe/&#34;&gt;https://www.servethehome.com/tesla-dojo-exa-scale-lossy-ai-network-using-the-tesla-transport-protocol-over-ethernet-ttpoe/&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Claude Code</title>
      <link>https://vsxen.github.io/posts/2025-06-01/</link>
      <pubDate>Sun, 01 Jun 2025 16:35:57 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-06-01/</guid>
      <description>&lt;p&gt;想找一个AI Terminal，必须支持自定义API_BASE_URL，&lt;a href=&#34;https://www.warp.dev&#34;&gt;warp&lt;/a&gt;这个不行。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/data-formulator&#34;&gt;Data Formulator&lt;/a&gt; MS的开源项目，利用AI做数据可视化。&lt;/p&gt;
&lt;p&gt;claude code发布了，和我之前思路类似，但是这个功能更丰富。&lt;/p&gt;
&lt;p&gt;查了下Gemini的API，主要是支持混合输出，当然也有兼容OPENAI的接口。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.tencent.com/developer/article/2168775&#34;&gt;通过硬件计数器，将性能提升3倍之旅&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;DeepSeek 发布了R1的小版本更新0528&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.railway.com/p/data-center-build-part-two&#34;&gt;https://blog.railway.com/p/data-center-build-part-two&lt;/a&gt;  裸金属上架&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart&#34;&gt;https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google I/O 2025 MS Build 2025</title>
      <link>https://vsxen.github.io/posts/2025-05-25/</link>
      <pubDate>Sun, 25 May 2025 16:53:13 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-05-25/</guid>
      <description>&lt;p&gt;这周是Google I/O 2025，发布了很多东西，Jules这个后续测试了下，很慢一般般。&lt;/p&gt;
&lt;p&gt;微软 Build 2025：WSL 项目正式开源。&lt;/p&gt;
&lt;p&gt;看了deepflow的相关进展，支持了http2。&lt;/p&gt;
&lt;p&gt;github Trending 上面好多Agent的项目，没时间测试了。&lt;/p&gt;
&lt;p&gt;小红书mcp，根据小红书web的接口做的，前端有js加密，没想到直接用pyexecjs这种方式&lt;/p&gt;
&lt;p&gt;简单玩了下sora &lt;img loading=&#34;lazy&#34; src=&#34;../../images/sora.webp&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ebpf.hamza-megahed.com/&#34;&gt;Engineering Everything with eBPF&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;想试试发公众号了，看到了&lt;a href=&#34;https://yuanqi.tencent.com/&#34;&gt;腾讯元器&lt;/a&gt; 和公众号打通了，但是没有坚持下来。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://nghiant3223.github.io/2025/04/15/go-scheduler.html&#34;&gt;https://nghiant3223.github.io/2025/04/15/go-scheduler.html&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>如何让LLM进入日产工作</title>
      <link>https://vsxen.github.io/posts/2025-05-18/</link>
      <pubDate>Sun, 18 May 2025 18:53:04 +0800</pubDate>
      <guid>https://vsxen.github.io/posts/2025-05-18/</guid>
      <description>&lt;p&gt;偶然发现github的console 有120+报错，怀疑是ublock的问题，怀疑是浏览器的问题，最后才发现是语雀浏览器插件导致的。&lt;/p&gt;
&lt;p&gt;Google launches Material 3 ，似乎已经没有之前那么惊艳了。&lt;/p&gt;
&lt;p&gt;看到open-telemetry准备支持arrow了，https://github.com/open-telemetry/otel-arrow 。
influxdb v3也正是这个发布了，告别了golang用rust重写，&lt;a href=&#34;https://docs.influxdata.com/influxdb3/core/get-started/&#34;&gt;新的版本&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;grafana 的dashbard 要是支持AI就好了，识别异常波动进行告警，找了一下发现了&lt;a href=&#34;https://github.com/grafana/grafana-llm-app&#34;&gt;这个&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Deepseek 发了一个硬件架构相关的论文， &lt;a href=&#34;https://www.arxiv.org/pdf/2505.09343&#34;&gt;Scaling Challenges and Reflections on Hardware for AI Architectures&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;看了下几个ebpf项目的进展，好像已经被AI掩盖过去了。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://etcd.io/blog/2025/announcing-etcd-3.6/&#34;&gt;etcd 发布了3.6&lt;/a&gt;，也是好久没有更新了，还把etcdctl的部分操作拆除到etcdutl了，&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.abhimanyu-saharan.com/posts/kubernetes-v1-33-fixes-a-10-year-old-image-pull-loophole&#34;&gt;Kubernetes v1.33 Fixes a 10-Year-Old Image Pull Loophole&lt;/a&gt;，有点夸张，就是多租户用到了同一个镜像，调度到同一个节点，kubelet就不会去验证镜像有没有拉取的权限。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.oschina.net/news/350003/ms-lays-off-typescript-veteran-in-latest-job-cuts&#34;&gt;在微软任职 18 年的资深 TypeScript 工程师被裁员&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://hanzilu.com/wordpress/?p=429&#34;&gt;大模型(LLM)驱动的APP自动化时代，使用xpath定位页面元素恐成为历史 &lt;/a&gt;，思路不错，我之前是想找一个从页面中提取文字，然后总结的工具，用视觉模型（OCR）也可以，但是我还是喜欢文本。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://engineering.fb.com/2024/08/05/data-center-engineering/roce-network-distributed-ai-training-at-scale/&#34;&gt;https://engineering.fb.com/2024/08/05/data-center-engineering/roce-network-distributed-ai-training-at-scale/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;生活&#34;&gt;生活&lt;/h2&gt;
&lt;p&gt;准备安装充电桩了，先看下怎么不被坑==&lt;/p&gt;
&lt;p&gt;想起来之前看的一个博主，Koala 聊开源。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
